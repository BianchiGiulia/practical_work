{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OJs9eEUwFhJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from gensim.models import KeyedVectors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V7STBMorjKr",
        "outputId": "78d6594f-645c-4b75-f9e0-caca74606d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlatvNT6wFhK"
      },
      "source": [
        "# Item embedding: TF-IDF matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BB8cGNRdwFhK"
      },
      "outputs": [],
      "source": [
        "news_train = '/content/drive/MyDrive/tesi/mind_small/news_test.tsv'\n",
        "news_test = '/content/drive/MyDrive/tesi/mind_small/news_train.tsv'\n",
        "\n",
        "\n",
        "def load_df(path):\n",
        "    if 'news' in path:\n",
        "        columns = ['News ID',\n",
        "                \"Category\",\n",
        "                \"SubCategory\",\n",
        "                \"Title\",\n",
        "                \"Abstract\",\n",
        "                \"URL\",\n",
        "                \"Title Entities\",\n",
        "                \"Abstract Entities\"]\n",
        "\n",
        "    elif 'behavior' in path:\n",
        "        columns = ['Impression ID',\n",
        "                \"User ID\",\n",
        "                \"Time\",\n",
        "                \"History\",\n",
        "                \"Impressions\"]\n",
        "    else:\n",
        "        return pd.read_csv(path, sep='\\t', header=None)\n",
        "\n",
        "    df = pd.read_csv(path, sep='\\t', header=None, names=columns)\n",
        "    return df\n",
        "news_train, news_test = load_df(news_train), load_df(news_test)\n",
        "data = pd.concat([news_train, news_test])\n",
        "inter = pd.read_csv('/content/drive/MyDrive/tesi/mind_small/mind_small15.inter', sep='\\t', header=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKeJihVtrejA",
        "outputId": "cb5dbe87-0248-494f-f056-b02d6a14250f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-a501c4aa866b>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['News ID'] = data['News ID'].astype(str)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25232 65238 25232\n",
            "(45600, 2)\n",
            "(25232, 2)\n"
          ]
        }
      ],
      "source": [
        "inter = inter[inter['label:float'] != 0] # keep only clicked articles\n",
        "#remove the N in news ID\n",
        "data['News ID'] = data['News ID'].str[1:]\n",
        "#drop everything but news ID & title\n",
        "col = ['News ID', 'Title']\n",
        "data = data[col]\n",
        "#make the news ID string\n",
        "data['News ID'] = data['News ID'].astype(str)\n",
        "inter['item_id:token'] = inter['item_id:token'].astype(str)\n",
        "unique_newsid = data['News ID'].unique()\n",
        "unique_itemid = inter['item_id:token'].unique()\n",
        "#check common news ID\n",
        "common = np.intersect1d(unique_newsid, unique_itemid)\n",
        "print(len(common), len(unique_newsid), len(unique_itemid))\n",
        "#keep in data only the one in common\n",
        "data = data[data['News ID'].isin(common)]\n",
        "print(data.shape)\n",
        "data = data.drop_duplicates(subset='News ID') #since it is made of both train and test\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "565DS9sX0DAi",
        "outputId": "c09fe93b-b3f3-4b52-e36b-228e32d1700e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfwmR6AnwFhL"
      },
      "outputs": [],
      "source": [
        "#preprocessing\n",
        "english_stopwords = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "pattern_punctuation = re.compile(r'[^\\w\\s]')\n",
        "pattern_numbers = re.compile(r'\\w*\\d+\\w*')\n",
        "pattern_short_words = re.compile(r'\\b\\w{1,3}\\b')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = pattern_punctuation.sub('', text)  # del punctuation\n",
        "    text = pattern_numbers.sub('', text)  # del numbers\n",
        "    text = pattern_short_words.sub('', text)  # del words with len <= 2\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in english_stopwords]  # del stopwords\n",
        "    words = [stemmer.stem(word) for word in words]  # stemming\n",
        "    return ' '.join(words)\n",
        "\n",
        "data['processed_title'] = data['Title'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz66qIY4wFhL"
      },
      "source": [
        "[TfidfVectorizer documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdhIkCTOwFhM"
      },
      "outputs": [],
      "source": [
        "#tfidf embedding\n",
        "tfidf_vectorizer = TfidfVectorizer(min_df=1,  stop_words='english', norm='l2')\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(data['processed_title'])\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
        "tfidf_df['News ID'] = data['News ID'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esFr8ZTPwFhM"
      },
      "outputs": [],
      "source": [
        "tfidf_df.reset_index(drop=True, inplace=True)\n",
        "#put column NEWS ID as first column\n",
        "tfidf_df = tfidf_df[ ['News ID'] + [ col for col in tfidf_df.columns if col != 'News ID' ] ]\n",
        "tfidf_df\n",
        "tfidf_df.to_csv('full_tf-idf.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yggCHZFywFhM"
      },
      "source": [
        "# User Embedding from Item Embedding\n",
        "\n",
        "1. aggregate  news + average:   $$ u = \\frac{1}{n} \\sum_{i=1}^{n} v_i $$ <br>\n",
        "where  $n$ is the number of items interacted with by the user, and $v_i$â€‹ is the TF-IDF vector of the i-th item <br><br><br>\n",
        "2. aggregate  news + weighted average based on label: $$ u = \\frac{\\sum_{i=1}^{n} w_i v_i}{\\sum_{i=1}^{n} w_i }  $$ <br>\n",
        "   e.g. $w_i = 0.1$ for item seen and not interacted and $w_i = 1$ otherwise <br>\n",
        "   <br><br>\n",
        "   e.g. a weight of 0.1 for item seen and not interacted (i.e. label = 0) scales down the contribution of this vector to the overall profile by 90%. <br><b>Q: Does this approach make sense with very sparse data?-> Maybe viable if embedding was denser e.g. word2vec or glove</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RORXlLZ8wFhM",
        "outputId": "1d6ca450-cb07-4d38-c204-d66e8a613912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#tfidf = tfidf_df\n",
        "tfidf = pd.read_csv('/content/drive/MyDrive/tesi/data/tfidf_emb.csv')\n",
        "inter = pd.read_csv('/content/drive/MyDrive/tesi/data/mind_small15.inter', sep='\\t', header=0)\n",
        "inter = inter[inter['label:float'] != 0]\n",
        "assert inter['item_id:token'].nunique() == tfidf.shape[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diCW_dVd0SbB"
      },
      "outputs": [],
      "source": [
        "tfidf_columns = tfidf.columns[:-1]\n",
        "#initialize user vector & counter\n",
        "user_tfidf_sum = pd.DataFrame(0, index=inter['user_id:token'].unique(), columns=tfidf_columns)\n",
        "user_interaction_counts = pd.Series(0, index=inter['user_id:token'].unique())\n",
        "\n",
        "#due to suicidal kernel, let's try incremental approach\n",
        "batch_size = 10000\n",
        "\n",
        "for start in range(0, inter.shape[0], batch_size):\n",
        "    end = min(start + batch_size, inter.shape[0])\n",
        "    chunk = inter.iloc[start:end]\n",
        "\n",
        "    user_news_chunk = pd.merge(chunk, tfidf, left_on='item_id:token', right_on='News ID')\n",
        "    #sum of interacted item (emb)\n",
        "    user_sum = user_news_chunk.groupby('user_id:token')[tfidf_columns].sum()\n",
        "    user_tfidf_sum.loc[user_sum.index] += user_sum\n",
        "    #count inter in chnk\n",
        "    user_counts = user_news_chunk['user_id:token'].value_counts()\n",
        "    user_interaction_counts[user_counts.index] += user_counts\n",
        "\n",
        "#average over seen items\n",
        "user_embeddings = user_tfidf_sum.div(user_interaction_counts, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqFKMUHXrejC",
        "outputId": "380ed3ef-d37b-4560-a7fb-cd005d4b6fc9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid:token</th>\n",
              "      <th>aaron</th>\n",
              "      <th>abandon</th>\n",
              "      <th>abl</th>\n",
              "      <th>abort</th>\n",
              "      <th>absolut</th>\n",
              "      <th>absurd</th>\n",
              "      <th>abus</th>\n",
              "      <th>accept</th>\n",
              "      <th>access</th>\n",
              "      <th>...</th>\n",
              "      <th>youth</th>\n",
              "      <th>youtub</th>\n",
              "      <th>youv</th>\n",
              "      <th>yovanovitch</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zion</th>\n",
              "      <th>zodiac</th>\n",
              "      <th>zone</th>\n",
              "      <th>zozo</th>\n",
              "      <th>zuckerberg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13740</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043779</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>91836</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006283</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>73700</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34670</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86331</th>\n",
              "      <td>73518</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86332</th>\n",
              "      <td>16981</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86333</th>\n",
              "      <td>17300</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86334</th>\n",
              "      <td>57759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86335</th>\n",
              "      <td>29272</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.272104</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>86336 rows Ã— 3001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       uid:token  aaron  abandon  abl     abort  absolut  absurd      abus  \\\n",
              "0          13740    0.0      0.0  0.0  0.043779      0.0     0.0  0.000000   \n",
              "1          91836    0.0      0.0  0.0  0.000000      0.0     0.0  0.006283   \n",
              "2          73700    0.0      0.0  0.0  0.000000      0.0     0.0  0.000000   \n",
              "3          34670    0.0      0.0  0.0  0.000000      0.0     0.0  0.000000   \n",
              "4           8125    0.0      0.0  0.0  0.000000      0.0     0.0  0.000000   \n",
              "...          ...    ...      ...  ...       ...      ...     ...       ...   \n",
              "86331      73518    0.0      0.0  0.0  0.000000      0.0     0.0  0.000000   \n",
              "86332      16981    0.0      0.0  0.0  0.000000      0.0     0.0  0.000000   \n",
              "86333      17300    0.0      0.0  0.0  0.000000      0.0     0.0  0.000000   \n",
              "86334      57759    0.0      0.0  0.0  0.000000      0.0     0.0  0.000000   \n",
              "86335      29272    0.0      0.0  0.0  0.000000      0.0     0.0  0.000000   \n",
              "\n",
              "       accept  access  ...  youth  youtub  youv  yovanovitch  zealand  zion  \\\n",
              "0         0.0     0.0  ...    0.0     0.0   0.0     0.000000      0.0   0.0   \n",
              "1         0.0     0.0  ...    0.0     0.0   0.0     0.000000      0.0   0.0   \n",
              "2         0.0     0.0  ...    0.0     0.0   0.0     0.000000      0.0   0.0   \n",
              "3         0.0     0.0  ...    0.0     0.0   0.0     0.000000      0.0   0.0   \n",
              "4         0.0     0.0  ...    0.0     0.0   0.0     0.000000      0.0   0.0   \n",
              "...       ...     ...  ...    ...     ...   ...          ...      ...   ...   \n",
              "86331     0.0     0.0  ...    0.0     0.0   0.0     0.000000      0.0   0.0   \n",
              "86332     0.0     0.0  ...    0.0     0.0   0.0     0.000000      0.0   0.0   \n",
              "86333     0.0     0.0  ...    0.0     0.0   0.0     0.000000      0.0   0.0   \n",
              "86334     0.0     0.0  ...    0.0     0.0   0.0     0.000000      0.0   0.0   \n",
              "86335     0.0     0.0  ...    0.0     0.0   0.0     0.272104      0.0   0.0   \n",
              "\n",
              "       zodiac  zone  zozo  zuckerberg  \n",
              "0         0.0   0.0   0.0         0.0  \n",
              "1         0.0   0.0   0.0         0.0  \n",
              "2         0.0   0.0   0.0         0.0  \n",
              "3         0.0   0.0   0.0         0.0  \n",
              "4         0.0   0.0   0.0         0.0  \n",
              "...       ...   ...   ...         ...  \n",
              "86331     0.0   0.0   0.0         0.0  \n",
              "86332     0.0   0.0   0.0         0.0  \n",
              "86333     0.0   0.0   0.0         0.0  \n",
              "86334     0.0   0.0   0.0         0.0  \n",
              "86335     0.0   0.0   0.0         0.0  \n",
              "\n",
              "[86336 rows x 3001 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_embeddings.rename(columns={'Unnamed: 0': 'uid:token'}, inplace=True)\n",
        "user_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuCXTW-brejC"
      },
      "outputs": [],
      "source": [
        "#prepare and save as atomic file\n",
        "user_embeddings = user_embeddings.set_index('uid:token')\n",
        "user_embeddings['user_emb:float_seq'] = user_embeddings.apply(lambda row: ' '.join(row.astype(str)), axis=1)\n",
        "user_embeddings.reset_index(inplace=True)\n",
        "user_embeddings = user_embeddings[['uid:token', 'user_emb:float_seq']]\n",
        "user_embeddings.to_csv('user_embeddings15.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwFFWrWbrejC",
        "outputId": "cc7bbe81-8312-412c-c565-bc66740d86f8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid:token</th>\n",
              "      <th>user_emb:float_seq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13740</td>\n",
              "      <td>0.0 0.0 0.0 0.0437792077908793 0.0 0.0 0.0 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>91836</td>\n",
              "      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0062834390437269 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>73700</td>\n",
              "      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34670</td>\n",
              "      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8125</td>\n",
              "      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86331</th>\n",
              "      <td>73518</td>\n",
              "      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86332</th>\n",
              "      <td>16981</td>\n",
              "      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86333</th>\n",
              "      <td>17300</td>\n",
              "      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86334</th>\n",
              "      <td>57759</td>\n",
              "      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86335</th>\n",
              "      <td>29272</td>\n",
              "      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>86336 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       uid:token                                 user_emb:float_seq\n",
              "0          13740  0.0 0.0 0.0 0.0437792077908793 0.0 0.0 0.0 0.0...\n",
              "1          91836  0.0 0.0 0.0 0.0 0.0 0.0 0.0062834390437269 0.0...\n",
              "2          73700  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....\n",
              "3          34670  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....\n",
              "4           8125  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....\n",
              "...          ...                                                ...\n",
              "86331      73518  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....\n",
              "86332      16981  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....\n",
              "86333      17300  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....\n",
              "86334      57759  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....\n",
              "86335      29272  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....\n",
              "\n",
              "[86336 rows x 2 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEs6l0e5rejC"
      },
      "outputs": [],
      "source": [
        "#same for item embedding\n",
        "item_emb = pd.read_csv('/Users/giulia/Desktop/tesi/tfidf_emb.csv', sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTD6Z7pKrejD"
      },
      "outputs": [],
      "source": [
        "item_emb = item_emb.set_index('News ID')\n",
        "#change name of columns\n",
        "item_emb.rename(columns={'News ID': 'iid:token'}, inplace=True)\n",
        "item_emb['item_emb:float_seq'] = item_emb.apply(lambda row: ' '.join(row.astype(str)), axis=1)\n",
        "item_emb.reset_index(inplace=True)\n",
        "item_emb = item_emb[['News ID', 'item_emb:float_seq']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyD0FOkQrejD",
        "outputId": "86c564a8-4367-42b5-9c97-ba4c60f2910f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>iid:token</th>\n",
              "      <th>item_emb:float_seq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>61837</td>\n",
              "      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53526</td>\n",
              "      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38324</td>\n",
              "      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2073</td>\n",
              "      <td>0.0 0.0 0.5667783692028184 0.0 0.0 0.0 0.0 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>49186</td>\n",
              "      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25227</th>\n",
              "      <td>5072</td>\n",
              "      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25228</th>\n",
              "      <td>31080</td>\n",
              "      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25229</th>\n",
              "      <td>62355</td>\n",
              "      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25230</th>\n",
              "      <td>63860</td>\n",
              "      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25231</th>\n",
              "      <td>61920</td>\n",
              "      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25232 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       iid:token                                 item_emb:float_seq\n",
              "0          61837  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....\n",
              "1          53526  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....\n",
              "2          38324  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....\n",
              "3           2073  0.0 0.0 0.5667783692028184 0.0 0.0 0.0 0.0 0.0...\n",
              "4          49186  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....\n",
              "...          ...                                                ...\n",
              "25227       5072  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....\n",
              "25228      31080  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....\n",
              "25229      62355  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....\n",
              "25230      63860  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....\n",
              "25231      61920  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....\n",
              "\n",
              "[25232 rows x 2 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#item_emb.rename(columns={'News ID': 'iid:token', 'item_emb:float_seq': 'item_emb:float_seq'}, inplace=True)\n",
        "item_emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYFX2-MDrejD"
      },
      "outputs": [],
      "source": [
        "item_emb.to_csv('item_embeddings15.csv', sep='\\t', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcbupeHArejD"
      },
      "source": [
        "# Pre-trained embeddings: <br>\n",
        "average of [GloVe](https://nlp.stanford.edu/projects/glove/) embedding weighted by tf-idf of words in the article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7v1NznfrejD"
      },
      "outputs": [],
      "source": [
        "#why don't they already put this will forever be a mistery to me\n",
        "#this need to be run only once\n",
        "def add_header_to_glove_file(input_file, output_file):\n",
        "    with open(input_file, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "    num_vectors = len(lines)\n",
        "    dimensions = 200\n",
        "    with open(output_file, 'w', encoding='utf-8') as file:\n",
        "        file.write(f\"{num_vectors} {dimensions}\\n\")\n",
        "        file.writelines(lines)\n",
        "#input_file = 'glove.twitter.27B/glove.twitter.27B.200d.txt'\n",
        "#output_file = 'glove.twitter.27B/glove.twitter.27B.200d.txt'\n",
        "#add_header_to_glove_file(input_file, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6p6YWJQPrejD"
      },
      "outputs": [],
      "source": [
        "glove_model = KeyedVectors.load_word2vec_format('glove.twitter.27B/glove.twitter.27B.200d.txt', binary=False) #1min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q909_7EGrejE"
      },
      "outputs": [],
      "source": [
        "#preprocessing\n",
        "english_stopwords = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "pattern_punctuation = re.compile(r'[^\\w\\s]')\n",
        "pattern_numbers = re.compile(r'\\w*\\d+\\w*')\n",
        "pattern_short_words = re.compile(r'\\b\\w{1,3}\\b')\n",
        "\n",
        "def glove_preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = pattern_punctuation.sub('', text)  # del punctuation\n",
        "    text = pattern_numbers.sub('', text)  # del numbers\n",
        "    text = pattern_short_words.sub('', text)  # del words with len <= 2\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in english_stopwords]  # del stopwords\n",
        "    #words = [stemmer.stem(word) for word in words]  #GloVe uses exact form of words\n",
        "    return words\n",
        "\n",
        "filtered_data['processed_title'] = filtered_data['Title'].apply(glove_preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSAwvQpPrejE",
        "outputId": "48632513-fca8-42ac-b75b-0d63121490c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/giulia/miniconda3/envs/recbole-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "def noop(doc):\n",
        "    return doc\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(min_df=5, max_df=0.95, stop_words=None, norm='l2', tokenizer=noop, preprocessor=noop)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(filtered_data['processed_title'])\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMtURtjUrejE"
      },
      "outputs": [],
      "source": [
        "#GloVe + TF-IDF Embeddings\n",
        "def get_weighted_average_glove(words, tfidf_vector, tfidf_feature_names):\n",
        "    word_vectors = np.zeros((glove_model.vector_size,))\n",
        "    total_weight = 0\n",
        "    for word in words:\n",
        "        if word in glove_model and word in tfidf_feature_names:\n",
        "            tfidf_weight = tfidf_vector[0, tfidf_feature_names.tolist().index(word)]\n",
        "            word_vectors += glove_model[word] * tfidf_weight #weighted sum\n",
        "            total_weight += tfidf_weight\n",
        "    if total_weight > 0:\n",
        "        word_vectors /= total_weight #averaged\n",
        "    return word_vectors #200D vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGQPMu3LrejE"
      },
      "outputs": [],
      "source": [
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "glove_embeddings = np.vstack([get_weighted_average_glove(doc, tfidf_matrix[i], tfidf_feature_names) for i, doc in enumerate(filtered_data['processed_title'])])\n",
        "filtered_data['glove_embeddings'] = list(glove_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AB1J0mX0rejE",
        "outputId": "74d6e2ab-73e4-4869-dfa5-5e19075f3388"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>iid:token</th>\n",
              "      <th>item_emb:float_seq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>61837</td>\n",
              "      <td>[-0.3018888610625763, -0.01441863232279384, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53526</td>\n",
              "      <td>[0.030755279004147814, -0.15293832795599122, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>38324</td>\n",
              "      <td>[-0.14559967716686759, -0.5394764966235572, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2073</td>\n",
              "      <td>[0.019193092035950033, 0.2334384066367838, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>49186</td>\n",
              "      <td>[-0.21076213154994625, 0.2232201614312713, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42409</th>\n",
              "      <td>42491</td>\n",
              "      <td>[-0.36951603754792617, -0.043448884240896844, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42410</th>\n",
              "      <td>13097</td>\n",
              "      <td>[0.17308648803038967, 0.22572657748324515, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42411</th>\n",
              "      <td>63550</td>\n",
              "      <td>[-0.08583496865807796, 0.009274802871813675, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42412</th>\n",
              "      <td>30345</td>\n",
              "      <td>[0.24341000616550446, 0.2530199885368347, -0.5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42413</th>\n",
              "      <td>30135</td>\n",
              "      <td>[0.1665432855428627, 0.41122543772045306, 0.12...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21156 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      iid:token                                 item_emb:float_seq\n",
              "2         61837  [-0.3018888610625763, -0.01441863232279384, -0...\n",
              "3         53526  [0.030755279004147814, -0.15293832795599122, -...\n",
              "4         38324  [-0.14559967716686759, -0.5394764966235572, -0...\n",
              "5          2073  [0.019193092035950033, 0.2334384066367838, -0....\n",
              "7         49186  [-0.21076213154994625, 0.2232201614312713, 0.0...\n",
              "...         ...                                                ...\n",
              "42409     42491  [-0.36951603754792617, -0.043448884240896844, ...\n",
              "42410     13097  [0.17308648803038967, 0.22572657748324515, -0....\n",
              "42411     63550  [-0.08583496865807796, 0.009274802871813675, 0...\n",
              "42412     30345  [0.24341000616550446, 0.2530199885368347, -0.5...\n",
              "42413     30135  [0.1665432855428627, 0.41122543772045306, 0.12...\n",
              "\n",
              "[21156 rows x 2 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#ITEM EMBEDDING as atomic file\n",
        "item_emb = filtered_data[['News ID', 'glove_embeddings']]\n",
        "item_emb = item_emb.rename(columns={'News ID': 'iid:token', 'glove_embeddings': 'item_emb:float_seq'}, inplace=False)\n",
        "item_emb['item_emb:float_seq'] = item_emb['item_emb:float_seq'].apply(lambda x: json.dumps(x.tolist()))\n",
        "item_emb.to_csv('item_embeddings15_glove.csv', sep='\\t', index=False)\n",
        "item_emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTnhfvi9rejF"
      },
      "outputs": [],
      "source": [
        "#USER EMBEDDING\n",
        "item_emb = pd.read_csv('/Users/giulia/Desktop/tesi/item_embeddings15_glove.csv', sep='\\t')\n",
        "item_emb['item_emb:float_seq'] = item_emb['item_emb:float_seq'].apply(lambda x: np.array(json.loads(x)))\n",
        "inter = pd.read_csv('/Users/giulia/Desktop/tesi/mind_small15/mind_small15.inter', sep='\\t', header=0)\n",
        "inter = inter[inter['item_id:token'].isin(item_emb['iid:token'])]\n",
        "assert inter['item_id:token'].nunique() == item_emb.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fIuAcnzrejF"
      },
      "outputs": [],
      "source": [
        "# Convert the merge key columns to string type\n",
        "inter['item_id:token'] = inter['item_id:token'].astype(str)\n",
        "item_emb['iid:token'] = item_emb['iid:token'].astype(str)\n",
        "user_item_emb = pd.merge(inter, item_emb, how='left', left_on='item_id:token', right_on='iid:token')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUnsP57CrejF"
      },
      "outputs": [],
      "source": [
        "batch_size = 10000\n",
        "batched_embeddings = pd.DataFrame()\n",
        "\n",
        "for start in range(0, user_item_emb.shape[0], batch_size):\n",
        "    end = min(start + batch_size, user_item_emb.shape[0])\n",
        "    batch = user_item_emb.iloc[start:end]\n",
        "\n",
        "    temp_df = pd.DataFrame(batch['item_emb:float_seq'].tolist(), index=batch.index)\n",
        "    temp_df['user_id:token'] = batch['user_id:token']\n",
        "\n",
        "    batched_embeddings = pd.concat([batched_embeddings, temp_df])\n",
        "\n",
        "#average over seen items\n",
        "user_embeddings = batched_embeddings.groupby('user_id:token').mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3NpYHcArejF"
      },
      "outputs": [],
      "source": [
        "user_embeddings.to_csv('user_embeddings15_glove.csv', sep='\\t', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "recbole-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}