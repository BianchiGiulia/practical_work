Sun 21 Apr 2024 19:38:10 INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 42
state = INFO
reproducibility = True
data_path = /Users/giulia/Desktop/tesi/mind_small15
checkpoint_dir = ./saved
show_progress = True
save_dataset = False
dataset_save_path = None
save_dataloaders = False
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 10
train_batch_size = 32
learner = adam
learning_rate = 0.001
train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'labeled', 'test': 'labeled'}}
repeatable = False
metrics = ['AUC', 'MAE', 'RMSE', 'LogLoss']
topk = [10]
valid_metric = AUC
valid_metric_bigger = True
eval_batch_size = 32
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = None
unload_col = None
unused_col = None
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = [0,inf)
item_inter_num_interval = [0,inf)
alias_of_user_id = None
alias_of_item_id = None
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = None
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
benchmark_filename = None

Other Hyper Parameters: 
worker = 0
wandb_project = recbole
shuffle = True
require_pow = False
enable_amp = False
enable_scaler = False
transform = None
embedding_size = 32
mlp_hidden_size = [128, 128, 128]
dropout_prob = 0.2
numerical_features = []
discretization = None
kg_reverse_r = False
entity_kg_num_interval = [0,inf)
relation_kg_num_interval = [0,inf)
MODEL_TYPE = ModelType.CONTEXT
device = cpu
l2_reg = 0.001
early_stopping_patience = 5
early_stopping_metric = AUC
log_level = DEBUG
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.VALUE
single_spec = True
local_rank = 0
valid_neg_sample_args = {'distribution': 'none', 'sample_num': 'none'}
test_neg_sample_args = {'distribution': 'none', 'sample_num': 'none'}


Sun 21 Apr 2024 19:39:21 INFO  mind_small15
The number of users: 86339
Average actions of users: 182.97368482012556
The number of items: 26938
Average actions of items: 586.4640457363478
The number of inters: 15797582
The sparsity of the dataset: 99.320767816568%
Remain Fields: ['user_id', 'item_id', 'label', 'timestamp']
Sun 21 Apr 2024 19:39:38 INFO  [Training]: train_batch_size = [32] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]
Sun 21 Apr 2024 19:39:38 INFO  [Evaluation]: eval_batch_size = [32] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'labeled', 'test': 'labeled'}}]
Sun 21 Apr 2024 19:39:38 INFO  DeepFM(
  (token_embedding_table): FMEmbedding(
    (embedding): Embedding(113277, 32)
  )
  (first_order_linear): FMFirstOrderLinear(
    (token_embedding_table): FMEmbedding(
      (embedding): Embedding(113277, 1)
    )
  )
  (fm): BaseFactorizationMachine()
  (mlp_layers): MLPLayers(
    (mlp_layers): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=64, out_features=128, bias=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Dropout(p=0.2, inplace=False)
      (7): Linear(in_features=128, out_features=128, bias=True)
      (8): ReLU()
    )
  )
  (deep_predict_layer): Linear(in_features=128, out_features=1, bias=True)
  (sigmoid): Sigmoid()
  (loss): BCEWithLogitsLoss()
)
Trainable parameters: 3779615
Sun 21 Apr 2024 20:45:30 INFO  epoch 0 training [time: 3793.45s, train loss: 72123.8454]
Sun 21 Apr 2024 20:46:08 INFO  epoch 0 evaluating [time: 37.48s, valid_score: 0.985200]
Sun 21 Apr 2024 20:46:08 INFO  valid result: 
auc : 0.9852    mae : 0.0334    rmse : 0.1654    logloss : 0.3202
Sun 21 Apr 2024 20:46:08 INFO  Saving current: ./saved/DeepFM-Apr-21-2024_19-42-14.pth
Sun 21 Apr 2024 20:56:19 INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 42
state = INFO
reproducibility = True
data_path = /Users/giulia/Desktop/tesi/mind_small15
checkpoint_dir = ./saved
show_progress = True
save_dataset = False
dataset_save_path = None
save_dataloaders = False
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 10
train_batch_size = 32
learner = adam
learning_rate = 0.001
train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'labeled', 'test': 'labeled'}}
repeatable = False
metrics = ['AUC', 'MAE', 'RMSE', 'LogLoss']
topk = [10]
valid_metric = AUC
valid_metric_bigger = True
eval_batch_size = 32
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = None
unload_col = None
unused_col = None
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = [0,inf)
item_inter_num_interval = [0,inf)
alias_of_user_id = None
alias_of_item_id = None
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = None
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
benchmark_filename = None

Other Hyper Parameters: 
worker = 0
wandb_project = recbole
shuffle = True
require_pow = False
enable_amp = False
enable_scaler = False
transform = None
embedding_size = 32
mlp_hidden_size = [128, 128, 128]
dropout_prob = 0.2
numerical_features = []
discretization = None
kg_reverse_r = False
entity_kg_num_interval = [0,inf)
relation_kg_num_interval = [0,inf)
MODEL_TYPE = ModelType.CONTEXT
device = cpu
l2_reg = 0.001
early_stopping_patience = 5
early_stopping_metric = AUC
log_level = DEBUG
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.VALUE
single_spec = True
local_rank = 0
valid_neg_sample_args = {'distribution': 'none', 'sample_num': 'none'}
test_neg_sample_args = {'distribution': 'none', 'sample_num': 'none'}


Sun 21 Apr 2024 20:57:45 INFO  mind_small15
The number of users: 86339
Average actions of users: 182.97368482012556
The number of items: 26938
Average actions of items: 586.4640457363478
The number of inters: 15797582
The sparsity of the dataset: 99.320767816568%
Remain Fields: ['user_id', 'item_id', 'label', 'timestamp']
Sun 21 Apr 2024 20:58:04 INFO  [Training]: train_batch_size = [32] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]
Sun 21 Apr 2024 20:58:04 INFO  [Evaluation]: eval_batch_size = [32] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'labeled', 'test': 'labeled'}}]
Sun 21 Apr 2024 21:59:52 INFO  epoch 0 training [time: 3697.44s, train loss: 72543.7085]
Sun 21 Apr 2024 22:00:28 INFO  epoch 0 evaluating [time: 35.19s, valid_score: 0.985100]
Sun 21 Apr 2024 22:00:28 INFO  valid result: 
auc : 0.9851    mae : 0.0338    rmse : 0.166    logloss : 0.3216
Sun 21 Apr 2024 22:00:28 INFO  Saving current: ./saved/DeepFM-Apr-21-2024_20-58-12.pth
Sun 21 Apr 2024 23:01:41 INFO  epoch 1 training [time: 3672.91s, train loss: 84947.7648]
Sun 21 Apr 2024 23:02:17 INFO  epoch 1 evaluating [time: 36.01s, valid_score: 0.984800]
Sun 21 Apr 2024 23:02:17 INFO  valid result: 
auc : 0.9848    mae : 0.0337    rmse : 0.1697    logloss : 0.3823
Mon 22 Apr 2024 00:04:48 INFO  epoch 2 training [time: 3751.02s, train loss: 98132.7527]
Mon 22 Apr 2024 00:05:24 INFO  epoch 2 evaluating [time: 36.27s, valid_score: 0.984000]
Mon 22 Apr 2024 00:05:24 INFO  valid result: 
auc : 0.984    mae : 0.0336    rmse : 0.1754    logloss : 0.4925
Mon 22 Apr 2024 01:07:31 INFO  epoch 3 training [time: 3727.07s, train loss: 110368.7987]
Mon 22 Apr 2024 01:08:08 INFO  epoch 3 evaluating [time: 37.10s, valid_score: 0.983300]
Mon 22 Apr 2024 01:08:08 INFO  valid result: 
auc : 0.9833    mae : 0.0365    rmse : 0.1839    logloss : 0.5735
Mon 22 Apr 2024 02:09:50 INFO  epoch 4 training [time: 3701.54s, train loss: 121551.8062]
Mon 22 Apr 2024 02:10:26 INFO  epoch 4 evaluating [time: 36.40s, valid_score: 0.982400]
Mon 22 Apr 2024 02:10:26 INFO  valid result: 
auc : 0.9824    mae : 0.0376    rmse : 0.1882    logloss : 0.6652
Mon 22 Apr 2024 03:12:04 INFO  epoch 5 training [time: 3698.48s, train loss: 130885.9389]
Mon 22 Apr 2024 03:12:41 INFO  epoch 5 evaluating [time: 36.73s, valid_score: 0.981800]
Mon 22 Apr 2024 03:12:41 INFO  valid result: 
auc : 0.9818    mae : 0.0376    rmse : 0.1898    logloss : 0.7627
Mon 22 Apr 2024 04:13:52 INFO  epoch 6 training [time: 3670.53s, train loss: 138356.7120]
Mon 22 Apr 2024 04:14:29 INFO  epoch 6 evaluating [time: 36.82s, valid_score: 0.980700]
Mon 22 Apr 2024 04:14:29 INFO  valid result: 
auc : 0.9807    mae : 0.0389    rmse : 0.1941    logloss : 0.8756
Mon 22 Apr 2024 05:15:35 INFO  epoch 7 training [time: 3666.70s, train loss: 145069.2395]
Mon 22 Apr 2024 05:16:12 INFO  epoch 7 evaluating [time: 36.52s, valid_score: 0.980200]
Mon 22 Apr 2024 05:16:12 INFO  valid result: 
auc : 0.9802    mae : 0.0385    rmse : 0.1938    logloss : 0.9491
Mon 22 Apr 2024 06:17:20 INFO  epoch 8 training [time: 3667.95s, train loss: 153020.1742]
Mon 22 Apr 2024 06:17:57 INFO  epoch 8 evaluating [time: 37.07s, valid_score: 0.979300]
Mon 22 Apr 2024 06:17:57 INFO  valid result: 
auc : 0.9793    mae : 0.0405    rmse : 0.1984    logloss : 0.9882
Mon 22 Apr 2024 07:19:38 INFO  epoch 9 training [time: 3701.26s, train loss: 160205.4209]
Mon 22 Apr 2024 07:20:15 INFO  epoch 9 evaluating [time: 37.29s, valid_score: 0.979300]
Mon 22 Apr 2024 07:20:15 INFO  valid result: 
auc : 0.9793    mae : 0.039    rmse : 0.1952    logloss : 1.036
Mon 22 Apr 2024 07:20:16 INFO  Loading model structure and parameters from ./saved/DeepFM-Apr-21-2024_20-58-12.pth
Mon 22 Apr 2024 07:20:54 INFO  OrderedDict([('auc', 0.985), ('mae', 0.034), ('rmse', 0.1666), ('logloss', 0.3239)])
